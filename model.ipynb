{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, merge\n",
    "from keras.models import Model,Sequential\n",
    "from layers import VGGNormalize,ReflectionPadding2D,Denormalize,conv_bn_relu,res_conv,dconv_bn_nolinear\n",
    "from loss import dummy_loss,StyleReconstructionRegularizer,FeatureReconstructionRegularizer,TVRegularizer\n",
    "\n",
    "import nets\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%reload_ext autoreload\n",
    "\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* Input 3 × 256 × 256\n",
    "* Reflection Padding (40 × 40) 3 × 336 × 336\n",
    "* 32 × 9 × 9 conv, stride 1 32 × 336 × 336\n",
    "* 64 × 3 × 3 conv, stride 2 64 × 168 × 168\n",
    "* 128 × 3 × 3 conv, stride 2 128 × 84 × 84\n",
    "* Residual block, 128 filters 128 × 80 × 80\n",
    "* Residual block, 128 filters 128 × 76 × 76\n",
    "* Residual block, 128 filters 128 × 72 × 72\n",
    "* Residual block, 128 filters 128 × 68 × 68\n",
    "* Residual block, 128 filters 128 × 64 × 64\n",
    "* 64 × 3 × 3 conv, stride 1/2 64 × 128 × 128\n",
    "* 32 × 3 × 3 conv, stride 1/2 32 × 256 × 256\n",
    "* 3 × 9 × 9 conv, stride 1 3 × 256 × 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG Model weights loaded.\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 256, 256, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "reflectionpadding2d_2 (Reflectio (None, 336, 336, 3)   0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 336, 336, 32)  7808        reflectionpadding2d_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_17 (BatchNorm (None, 336, 336, 32)  128         convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 336, 336, 32)  0           batchnormalization_17[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 168, 168, 64)  165952      activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_18 (BatchNorm (None, 168, 168, 64)  256         convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 168, 168, 64)  0           batchnormalization_18[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_16 (Convolution2D) (None, 84, 84, 128)   73856       activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_19 (BatchNorm (None, 84, 84, 128)   512         convolution2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 84, 84, 128)   0           batchnormalization_19[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_17 (Convolution2D) (None, 82, 82, 128)   147584      activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_20 (BatchNorm (None, 82, 82, 128)   512         convolution2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 82, 82, 128)   0           batchnormalization_20[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D) (None, 80, 80, 128)   147584      activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_6 (Cropping2D)        (None, 80, 80, 128)   0           activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_21 (BatchNorm (None, 80, 80, 128)   512         convolution2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "merge_7 (Merge)                  (None, 80, 80, 128)   0           cropping2d_6[0][0]               \n",
      "                                                                   batchnormalization_21[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_19 (Convolution2D) (None, 78, 78, 128)   147584      merge_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_22 (BatchNorm (None, 78, 78, 128)   512         convolution2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 78, 78, 128)   0           batchnormalization_22[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_20 (Convolution2D) (None, 76, 76, 128)   147584      activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_7 (Cropping2D)        (None, 76, 76, 128)   0           merge_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_23 (BatchNorm (None, 76, 76, 128)   512         convolution2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "merge_8 (Merge)                  (None, 76, 76, 128)   0           cropping2d_7[0][0]               \n",
      "                                                                   batchnormalization_23[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_21 (Convolution2D) (None, 74, 74, 128)   147584      merge_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_24 (BatchNorm (None, 74, 74, 128)   512         convolution2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 74, 74, 128)   0           batchnormalization_24[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_22 (Convolution2D) (None, 72, 72, 128)   147584      activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_8 (Cropping2D)        (None, 72, 72, 128)   0           merge_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_25 (BatchNorm (None, 72, 72, 128)   512         convolution2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "merge_9 (Merge)                  (None, 72, 72, 128)   0           cropping2d_8[0][0]               \n",
      "                                                                   batchnormalization_25[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_23 (Convolution2D) (None, 70, 70, 128)   147584      merge_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_26 (BatchNorm (None, 70, 70, 128)   512         convolution2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 70, 70, 128)   0           batchnormalization_26[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_24 (Convolution2D) (None, 68, 68, 128)   147584      activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_9 (Cropping2D)        (None, 68, 68, 128)   0           merge_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_27 (BatchNorm (None, 68, 68, 128)   512         convolution2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "merge_10 (Merge)                 (None, 68, 68, 128)   0           cropping2d_9[0][0]               \n",
      "                                                                   batchnormalization_27[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_25 (Convolution2D) (None, 66, 66, 128)   147584      merge_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_28 (BatchNorm (None, 66, 66, 128)   512         convolution2d_25[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 66, 66, 128)   0           batchnormalization_28[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_26 (Convolution2D) (None, 64, 64, 128)   147584      activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_10 (Cropping2D)       (None, 64, 64, 128)   0           merge_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_29 (BatchNorm (None, 64, 64, 128)   512         convolution2d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "merge_11 (Merge)                 (None, 64, 64, 128)   0           cropping2d_10[0][0]              \n",
      "                                                                   batchnormalization_29[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "deconvolution2d_4 (Deconvolution (None, 128, 128, 64)  73792       merge_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_30 (BatchNorm (None, 128, 128, 64)  256         deconvolution2d_4[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 128, 128, 64)  0           batchnormalization_30[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "deconvolution2d_5 (Deconvolution (None, 256, 256, 32)  18464       activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_31 (BatchNorm (None, 256, 256, 32)  128         deconvolution2d_5[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 256, 256, 32)  0           batchnormalization_31[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "deconvolution2d_6 (Deconvolution (None, 256, 256, 3)   7779        activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_32 (BatchNorm (None, 256, 256, 3)   12          deconvolution2d_6[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 256, 256, 3)   0           batchnormalization_32[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "transform_output (Denormalize)   (None, 256, 256, 3)   0           activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "merge_12 (Merge)                 (None, 256, 256, 3)   0           transform_output[0][0]           \n",
      "                                                                   input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "vgg_normalize (VGGNormalize)     (None, 256, 256, 3)   0           merge_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, 256, 256, 64)  1792        vgg_normalize[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, 256, 256, 64)  36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 128, 128, 64)  0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, 128, 128, 128) 73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, 128, 128, 128) 147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 64, 64, 128)   0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, 64, 64, 256)   295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, 64, 64, 256)   590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, 64, 64, 256)   590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 32, 32, 256)   0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, 32, 32, 512)   1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, 32, 32, 512)   2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, 32, 32, 512)   2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 16, 16, 512)   0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, 16, 16, 512)   2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, 16, 16, 512)   2359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, 16, 16, 512)   2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, 8, 8, 512)     0           block5_conv3[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 16,544,591\n",
      "Trainable params: 1,826,697\n",
      "Non-trainable params: 14,717,894\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model = nets.image_transform_net()\n",
    "# print model.summary() \n",
    "\n",
    "#if tranning\n",
    "\n",
    "model = nets.loss_net(model.output,model.input)\n",
    "\n",
    "print model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "Found 3 images belonging to 1 classes.\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 4s - loss: 40637.5508\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 4s - loss: 35499.4023\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 3s - loss: 33949.3789\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 3s - loss: 32696.1738\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 4s - loss: 32549.5469\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 3s - loss: 32835.9688\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 3s - loss: 32130.3184\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 4s - loss: 30901.1016\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 4s - loss: 30110.5430\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 3s - loss: 29829.4102\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 3s - loss: 29575.2969\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 3s - loss: 29459.6016\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 3s - loss: 29598.6660\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 3s - loss: 29402.3320\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 3s - loss: 28942.7148\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 4s - loss: 28468.9062\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 3s - loss: 27858.4570\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 3s - loss: 27094.7910\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 3s - loss: 26515.9004\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 3s - loss: 26349.7129\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 4s - loss: 25818.0117\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 3s - loss: 25545.4355\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 3s - loss: 25592.3652\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 3s - loss: 25682.2852\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 3s - loss: 25630.8750\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 3s - loss: 25392.4414\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 3s - loss: 25057.1582\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 3s - loss: 24687.5684\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 3s - loss: 24407.7031\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 3s - loss: 24264.4238\n",
      "(40637.55078125, 148.69244623184204)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 4s - loss: 40237.7930\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 3s - loss: 39243.4688\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 3s - loss: 37829.5781\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 3s - loss: 36286.4258\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 3s - loss: 34609.2148\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 4s - loss: 32948.6797\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 4s - loss: 31530.8867\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 3s - loss: 30364.4805\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 3s - loss: 29053.9355\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 3s - loss: 27733.5664\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 3s - loss: 26764.0000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 3s - loss: 26034.2949\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 4s - loss: 25718.3867\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 3s - loss: 25497.8320\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 3s - loss: 25435.7227\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 3s - loss: 25303.5742\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 3s - loss: 25086.2852\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 3s - loss: 24434.2520\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 3s - loss: 23687.7617\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 3s - loss: 23270.1328\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 3s - loss: 23150.0117\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 3s - loss: 22984.0078\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 3s - loss: 22854.4805\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 3s - loss: 22757.7266\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 3s - loss: 22650.9219\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 3s - loss: 22567.3887\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 3s - loss: 22512.3809\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 3s - loss: 22465.2871\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 3s - loss: 22479.4258\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 3s - loss: 22501.8945\n",
      "(40237.79296875, 142.0217580795288)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s - loss: 34110.4844\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 3s - loss: 31877.3184\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 3s - loss: 28481.4355\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 3s - loss: 25435.8750\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 3s - loss: 24254.1973\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 3s - loss: 23994.5078\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 3s - loss: 23949.5859\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 3s - loss: 23963.7285\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 3s - loss: 23972.6543\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 3s - loss: 23960.8672\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 3s - loss: 23913.5020\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 3s - loss: 23820.8887\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 3s - loss: 23696.8359\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 3s - loss: 23529.7305\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 3s - loss: 23332.2109\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 3s - loss: 23120.6504\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 3s - loss: 22905.4375\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 3s - loss: 22689.7227\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 3s - loss: 22529.4492\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 3s - loss: 22399.8125\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 3s - loss: 22301.7285\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 3s - loss: 22224.9043\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 3s - loss: 22166.1836\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 3s - loss: 22103.0977\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 3s - loss: 22028.4922\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 3s - loss: 21925.6875\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 3s - loss: 21788.4082\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 3s - loss: 21632.8613\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 3s - loss: 21475.0879\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 3s - loss: 21336.2988\n",
      "(34110.484375, 139.0456759929657)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s - loss: 35423.5547\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 3s - loss: 35058.3047\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 3s - loss: 34503.8281\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 3s - loss: 33780.7109\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 3s - loss: 32951.0977\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 3s - loss: 32105.8652\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 3s - loss: 31355.8789\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 3s - loss: 30669.0781\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 3s - loss: 29919.6367\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 3s - loss: 29040.8652\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 3s - loss: 28141.4199\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 3s - loss: 27369.9395\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 3s - loss: 26816.0391\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 3s - loss: 26372.3203\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 3s - loss: 25879.7754\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 3s - loss: 25464.8027\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 3s - loss: 25100.0156\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 3s - loss: 24748.4727\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 3s - loss: 24462.3418\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 3s - loss: 24296.4375\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 3s - loss: 24260.2246\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 3s - loss: 24320.1797\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 3s - loss: 24398.7051\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 3s - loss: 24401.7832\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 3s - loss: 24281.2422\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 3s - loss: 24076.8125\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 3s - loss: 23867.0918\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 3s - loss: 23666.4141\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 3s - loss: 23484.6719\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 3s - loss: 23306.1445\n",
      "(35423.5546875, 138.5418200492859)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s - loss: 32190.1484\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 3s - loss: 31891.5645\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 3s - loss: 31381.4746\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 3s - loss: 30753.7930\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 3s - loss: 30125.2617\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 3s - loss: 29553.2363\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 3s - loss: 28964.7773\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 3s - loss: 28228.0039\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 3s - loss: 27569.5430\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 3s - loss: 27068.4297\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 3s - loss: 26606.2930\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 3s - loss: 26190.4160\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 3s - loss: 25856.2266\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 3s - loss: 25563.7480\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 3s - loss: 25278.9336\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 3s - loss: 24995.9043\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 3s - loss: 24673.0938\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 3s - loss: 24361.3887\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 3s - loss: 24080.3672\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 3s - loss: 23824.5586\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 3s - loss: 23597.5000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 3s - loss: 23431.4727\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 3s - loss: 23280.9414\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 3s - loss: 23118.3379\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 3s - loss: 22948.9824\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 3s - loss: 22784.1562\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 3s - loss: 22671.6172\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 3s - loss: 22590.5469\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 3s - loss: 22501.1055\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 3s - loss: 22413.5957\n",
      "(32190.1484375, 138.28606581687927)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s - loss: 24727.3301\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 3s - loss: 24728.8887\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 3s - loss: 24665.8066\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 3s - loss: 24559.3047\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 3s - loss: 24395.1758\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 3s - loss: 24182.9531\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 3s - loss: 23945.9121\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 3s - loss: 23708.0293\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 3s - loss: 23460.3066\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 3s - loss: 23224.8516\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 3s - loss: 23002.3984\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 3s - loss: 22803.3516\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 3s - loss: 22611.1191\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 3s - loss: 22418.2070\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 3s - loss: 22231.3008\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 3s - loss: 22068.1992\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 3s - loss: 21924.9883\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 3s - loss: 21798.1152\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 3s - loss: 21695.6055\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 3s - loss: 21617.3906\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 3s - loss: 21547.9258\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 3s - loss: 21484.2344\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 3s - loss: 21425.8652\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 3s - loss: 21377.2051\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 3s - loss: 21332.3867\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 3s - loss: 21288.3047\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 3s - loss: 21234.6016\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 3s - loss: 21181.5742\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 3s - loss: 21133.6777\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 3s - loss: 21084.2148\n",
      "(24727.330078125, 138.9111988544464)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s - loss: 26028.1387\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 3s - loss: 25931.6348\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 3s - loss: 25570.5234\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 3s - loss: 25038.5254\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 3s - loss: 24520.8516\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 3s - loss: 24044.7988\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 3s - loss: 23537.6504\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 3s - loss: 23278.2285\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 3s - loss: 23057.7949\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 3s - loss: 22835.1094\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 3s - loss: 22650.9844\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 3s - loss: 22513.9277\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 3s - loss: 22366.3516\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 4s - loss: 22210.7305\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 3s - loss: 22057.5742\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 3s - loss: 21923.3320\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 3s - loss: 21808.2676\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 3s - loss: 21717.9160\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 3s - loss: 21666.6562\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 3s - loss: 21640.6543\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 3s - loss: 21623.6875\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 3s - loss: 21600.2441\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 3s - loss: 21586.3750\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 3s - loss: 21582.3867\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 3s - loss: 21565.4238\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 3s - loss: 21533.2051\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 3s - loss: 21485.7891\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 3s - loss: 21412.5391\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 3s - loss: 21315.4238\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 3s - loss: 21189.2598\n",
      "(26028.138671875, 137.19442105293274)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s - loss: 25490.3477\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 3s - loss: 25545.3262\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 3s - loss: 25485.5586\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 3s - loss: 25317.6465\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 3s - loss: 25052.6699\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 3s - loss: 24710.9551\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 3s - loss: 24304.5996\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 3s - loss: 23853.1230\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 3s - loss: 23420.3555\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 3s - loss: 23043.2285\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 3s - loss: 22751.4805\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 3s - loss: 22522.8301\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 3s - loss: 22316.8926\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 3s - loss: 22109.2559\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 3s - loss: 21837.7930\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 3s - loss: 21507.5410\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 3s - loss: 21266.1191\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 3s - loss: 21137.4941\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 3s - loss: 21135.5586\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 3s - loss: 21149.7891\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 3s - loss: 21151.4141\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 3s - loss: 21121.7832\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 3s - loss: 21029.1641\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 3s - loss: 20883.7949\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 3s - loss: 20715.2734\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 3s - loss: 20507.2969\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 3s - loss: 20276.7246\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 3s - loss: 20038.8203\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 3s - loss: 19875.8945\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 3s - loss: 19787.8184\n",
      "(25490.34765625, 138.227774143219)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s - loss: 20662.7910\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 3s - loss: 20551.5273\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 3s - loss: 20453.8145\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 3s - loss: 20374.6953\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 3s - loss: 20315.7266\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 3s - loss: 20277.3105\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 3s - loss: 20247.3828\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 3s - loss: 20218.4004\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 3s - loss: 20200.0547\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 3s - loss: 20183.5137\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 3s - loss: 20166.9102\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 3s - loss: 20154.4863\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 3s - loss: 20139.8398\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 3s - loss: 20122.2109\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 3s - loss: 20105.1914\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 3s - loss: 20084.6758\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 3s - loss: 20063.3730\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 3s - loss: 20038.0879\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 3s - loss: 20011.0469\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 3s - loss: 19983.0625\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 3s - loss: 19954.8008\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 3s - loss: 19925.8867\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 3s - loss: 19896.0664\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 3s - loss: 19864.8594\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 3s - loss: 19831.8867\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 3s - loss: 19796.7832\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 3s - loss: 19759.7695\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 3s - loss: 19721.2598\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 3s - loss: 19681.6855\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 3s - loss: 19639.4453\n",
      "(20662.791015625, 137.81692099571228)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s - loss: 22975.1836\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 3s - loss: 22844.9453\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 3s - loss: 22660.8418\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 3s - loss: 22423.5566\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 3s - loss: 22131.0684\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 3s - loss: 21775.7207\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 3s - loss: 21461.6250\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 3s - loss: 21259.8145\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 3s - loss: 21082.9141\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 3s - loss: 20942.2480\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 3s - loss: 20844.3828\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 3s - loss: 20765.4648\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 3s - loss: 20698.5449\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 3s - loss: 20644.4102\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 3s - loss: 20590.6152\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 3s - loss: 20537.4102\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 3s - loss: 20482.1406\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 3s - loss: 20439.8750\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 3s - loss: 20405.3438\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 3s - loss: 20370.4863\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 3s - loss: 20334.2266\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 3s - loss: 20295.5371\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 3s - loss: 20260.5273\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 3s - loss: 20222.4375\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 3s - loss: 20178.4531\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 3s - loss: 20131.4082\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 3s - loss: 20087.4492\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 3s - loss: 20037.2852\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 3s - loss: 19973.5195\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 3s - loss: 19897.8281\n",
      "(22975.18359375, 138.345782995224)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s - loss: 20189.2422\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 3s - loss: 20161.8633\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 3s - loss: 20118.4629\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 3s - loss: 20060.9844\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 3s - loss: 19989.0586\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 3s - loss: 19909.8184\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 3s - loss: 19816.1914\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 3s - loss: 19704.1484\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 3s - loss: 19565.4004\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 3s - loss: 19424.2891\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 3s - loss: 19329.4688\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 3s - loss: 19312.1074\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 3s - loss: 19330.8906\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 3s - loss: 19344.1953\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 3s - loss: 19300.7109\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 3s - loss: 19164.8613\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 3s - loss: 18942.2812\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 3s - loss: 18671.0820\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 3s - loss: 18388.0527\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 3s - loss: 18133.1445\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 3s - loss: 17977.9258\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 3s - loss: 17910.8477\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 3s - loss: 17891.2578\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 3s - loss: 17894.7461\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 3s - loss: 17902.8438\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 3s - loss: 17899.8438\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 3s - loss: 17883.5312\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 3s - loss: 17857.3203\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 3s - loss: 17816.2832\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 3s - loss: 17766.2227\n",
      "(20189.2421875, 137.43625783920288)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s - loss: 18429.0820\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 4s - loss: 18423.3281\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 4s - loss: 18415.3555\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 4s - loss: 18404.6445\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 4s - loss: 18395.9004\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 4s - loss: 18397.9375\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 3s - loss: 18406.7227\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 4s - loss: 18413.7656\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 3s - loss: 18409.8809\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 4s - loss: 18393.9180\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 4s - loss: 18364.1621\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 3s - loss: 18321.9277\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 3s - loss: 18271.3164\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 3s - loss: 18218.7773\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 3s - loss: 18166.2988\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 3s - loss: 18118.6445\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 4s - loss: 18077.9023\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 3s - loss: 18041.6172\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 3s - loss: 18010.5410\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 3s - loss: 17981.5957\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 4s - loss: 17954.5391\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 3s - loss: 17932.6426\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 4s - loss: 17912.9590\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 4s - loss: 17893.3203\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 4s - loss: 17874.6836\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 4s - loss: 17856.6680\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 3s - loss: 17836.7441\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 3s - loss: 17814.2988\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 3s - loss: 17788.8066\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 3s - loss: 17760.5293\n",
      "(18429.08203125, 145.82136988639832)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 4s - loss: 20708.1797\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 4s - loss: 20635.6094\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 3s - loss: 20499.4629\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 3s - loss: 20320.0469\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 3s - loss: 20110.0137\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 3s - loss: 19889.9961\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 3s - loss: 19687.9766\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 3s - loss: 19502.5039\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 3s - loss: 19328.1680\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 3s - loss: 19169.8516\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 4s - loss: 19025.6191\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 3s - loss: 18891.3770\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 3s - loss: 18772.6406\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 3s - loss: 18670.5137\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 3s - loss: 18579.6367\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 3s - loss: 18498.8652\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 3s - loss: 18424.3047\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 3s - loss: 18352.8848\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 3s - loss: 18286.6562\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 4s - loss: 18223.9570\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 3s - loss: 18168.1367\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 3s - loss: 18121.5586\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 3s - loss: 18084.6211\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 3s - loss: 18057.8867\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 3s - loss: 18037.5254\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 4s - loss: 18029.7695\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 4s - loss: 18034.2852\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 4s - loss: 18049.0605\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 4s - loss: 18070.5879\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 4s - loss: 18094.0059\n",
      "(20708.1796875, 146.54592609405518)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 4s - loss: 18698.1289\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 4s - loss: 18719.4668\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 4s - loss: 18730.6133\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 4s - loss: 18732.3887\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 4s - loss: 18725.6934\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 3s - loss: 18710.2852\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 4s - loss: 18686.0820\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 3s - loss: 18652.9551\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 3s - loss: 18610.4297\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 3s - loss: 18560.5820\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 3s - loss: 18503.2129\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 3s - loss: 18439.1641\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 3s - loss: 18370.5742\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 3s - loss: 18297.2637\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 3s - loss: 18219.5762\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 3s - loss: 18135.5156\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 4s - loss: 18047.1562\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 3s - loss: 17958.7832\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 3s - loss: 17868.2891\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 4s - loss: 17783.7129\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 4s - loss: 17703.0859\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 3s - loss: 17632.2109\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 4s - loss: 17573.8613\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 4s - loss: 17533.0469\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 4s - loss: 17509.0703\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 4s - loss: 17495.2500\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 3s - loss: 17494.1953\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 3s - loss: 17498.1816\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 3s - loss: 17503.2188\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 3s - loss: 17505.8008\n",
      "(18698.12890625, 144.78057599067688)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s - loss: 19131.0312\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 4s - loss: 19132.2305\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 4s - loss: 19092.1387\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 4s - loss: 19017.0234\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 4s - loss: 18913.6172\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 4s - loss: 18791.2559\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 4s - loss: 18654.5020\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 4s - loss: 18508.0254\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 4s - loss: 18365.9141\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 4s - loss: 18241.0430\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 4s - loss: 18138.9570\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 4s - loss: 18052.9102\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 4s - loss: 17979.6680\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 4s - loss: 17917.8242\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 4s - loss: 17867.0156\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 4s - loss: 17822.5176\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 4s - loss: 17783.2383\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 4s - loss: 17744.0273\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 4s - loss: 17707.2676\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 4s - loss: 17673.4766\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 4s - loss: 17638.8730\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 4s - loss: 17608.6953\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 4s - loss: 17581.7090\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 4s - loss: 17558.6387\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 4s - loss: 17538.3359\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 4s - loss: 17523.9980\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 4s - loss: 17509.4062\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 4s - loss: 17493.4531\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 4s - loss: 17474.2305\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 4s - loss: 17444.7578\n",
      "(19131.03125, 155.88499903678894)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s - loss: 17459.6289\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 3s - loss: 17403.6992\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 3s - loss: 17338.6660\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 3s - loss: 17266.0781\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 3s - loss: 17186.8516\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 3s - loss: 17105.1582\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 3s - loss: 17024.8848\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 3s - loss: 16947.4629\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 3s - loss: 16872.0938\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 3s - loss: 16797.1035\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 3s - loss: 16723.1914\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 3s - loss: 16649.1719\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 3s - loss: 16572.3926\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 3s - loss: 16494.3125\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 3s - loss: 16419.0605\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 3s - loss: 16349.9932\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 3s - loss: 16285.9902\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 3s - loss: 16221.3896\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 3s - loss: 16159.6328\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 3s - loss: 16099.7832\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 3s - loss: 16048.5859\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 3s - loss: 15993.8750\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 3s - loss: 15935.5195\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 3s - loss: 15869.7178\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 3s - loss: 15798.4727\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 3s - loss: 15726.0215\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 3s - loss: 15647.6875\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 3s - loss: 15571.4678\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 3s - loss: 15491.4502\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 3s - loss: 15418.6807\n",
      "(17459.62890625, 141.00311303138733)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s - loss: 17525.9707\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 3s - loss: 17568.6953\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 3s - loss: 17589.9570\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 3s - loss: 17591.2207\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 3s - loss: 17571.6660\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 3s - loss: 17531.1309\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 3s - loss: 17469.8691\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 4s - loss: 17385.7129\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 3s - loss: 17282.5801\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 3s - loss: 17170.2812\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 3s - loss: 17053.0195\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 3s - loss: 16925.6074\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 3s - loss: 16800.9922\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 3s - loss: 16684.5176\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 3s - loss: 16588.7910\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 3s - loss: 16497.7852\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 3s - loss: 16421.5215\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 3s - loss: 16360.9951\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 3s - loss: 16312.9385\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 3s - loss: 16276.7305\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 3s - loss: 16251.4521\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 3s - loss: 16223.6709\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 3s - loss: 16197.8809\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 3s - loss: 16174.8418\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 3s - loss: 16153.9834\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 3s - loss: 16130.5146\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 3s - loss: 16107.6445\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 3s - loss: 16085.4141\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 3s - loss: 16062.4258\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 3s - loss: 16038.9824\n",
      "(17525.970703125, 139.97481083869934)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s - loss: 19288.7344\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 3s - loss: 19243.6387\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 3s - loss: 19155.0391\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 3s - loss: 19010.0078\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 3s - loss: 18791.9160\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 3s - loss: 18485.6836\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 3s - loss: 18053.9883\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 3s - loss: 17236.2695\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 3s - loss: 16021.3730\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 3s - loss: 15236.1543\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 3s - loss: 14807.4336\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 3s - loss: 14465.2334\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 3s - loss: 14213.7109\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 3s - loss: 14113.9424\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 3s - loss: 14059.8662\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 3s - loss: 14028.6348\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 3s - loss: 13997.1709\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 3s - loss: 13970.5703\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 3s - loss: 13951.4258\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 3s - loss: 13941.4844\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 3s - loss: 13950.0479\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 3s - loss: 13950.0986\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 3s - loss: 13972.6943\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 3s - loss: 13987.3574\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 3s - loss: 13991.4473\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 3s - loss: 13993.1113\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 3s - loss: 13988.2832\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 3s - loss: 13970.8779\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 3s - loss: 13941.3125\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 3s - loss: 13909.0508\n",
      "(19288.734375, 139.2624490261078)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s - loss: 30434.7344\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 4s - loss: 30562.0254\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 4s - loss: 30039.2422\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 4s - loss: 28900.8359\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 4s - loss: 27396.9160\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 4s - loss: 25851.2031\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 4s - loss: 24156.6680\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 3s - loss: 21751.6973\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 3s - loss: 19326.7227\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 3s - loss: 17986.7227\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 3s - loss: 16609.2188\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 3s - loss: 15986.3945\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 3s - loss: 15812.4619\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 4s - loss: 15933.0449\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 4s - loss: 16116.8701\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 3s - loss: 16253.5205\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 3s - loss: 16342.4463\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 3s - loss: 16387.9180\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 3s - loss: 16398.5117\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 4s - loss: 16377.7158\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 3s - loss: 16326.7031\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 3s - loss: 16255.6025\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 3s - loss: 16168.6709\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 4s - loss: 16094.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 3s - loss: 16037.2275\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 3s - loss: 15999.3438\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 4s - loss: 15981.3506\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 3s - loss: 15979.9658\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 4s - loss: 15980.9590\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 4s - loss: 15984.5469\n",
      "(30434.734375, 145.28128695487976)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s - loss: 27934.3613\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 3s - loss: 27765.6484\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 3s - loss: 27402.0312\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 3s - loss: 26920.7715\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 3s - loss: 26250.8262\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 3s - loss: 24935.9824\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 3s - loss: 22952.7656\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 4s - loss: 21653.4824\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 3s - loss: 20671.4180\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 3s - loss: 19870.6113\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 3s - loss: 19234.7852\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 4s - loss: 18823.9316\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 3s - loss: 18525.4199\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 4s - loss: 18224.3906\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 3s - loss: 17943.2344\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 3s - loss: 17725.1797\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 3s - loss: 17543.1660\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 4s - loss: 17393.6602\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 4s - loss: 17275.8711\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 4s - loss: 17177.9102\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 4s - loss: 17095.5996\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 3s - loss: 17030.6914\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 3s - loss: 16966.3184\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 4s - loss: 16897.7832\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 3s - loss: 16837.2500\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 3s - loss: 16814.3145\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 3s - loss: 16806.3770\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 4s - loss: 16815.6367\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 4s - loss: 16841.1777\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 4s - loss: 16859.1133\n",
      "(27934.361328125, 145.65047311782837)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s - loss: 17251.2363\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 4s - loss: 17593.5625\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 4s - loss: 17868.3105\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 4s - loss: 18006.4199\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 4s - loss: 18027.5371\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 4s - loss: 17987.1309\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 4s - loss: 17907.9668\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 4s - loss: 17791.1680\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 4s - loss: 17636.4746\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 4s - loss: 17449.8926\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 4s - loss: 17240.5371\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 4s - loss: 17012.9434\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 4s - loss: 16772.6465\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 3s - loss: 16528.0781\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 4s - loss: 16301.7354\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 4s - loss: 16108.5254\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 3s - loss: 15925.9229\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 3s - loss: 15777.5146\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 3s - loss: 15646.0801\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 3s - loss: 15540.5703\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 3s - loss: 15458.7617\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 3s - loss: 15393.8184\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 3s - loss: 15350.5557\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 3s - loss: 15337.1738\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 3s - loss: 15337.0771\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 3s - loss: 15340.0811\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 3s - loss: 15345.8379\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 3s - loss: 15347.6855\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 3s - loss: 15343.4033\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 3s - loss: 15330.4404\n",
      "(17251.236328125, 143.6939959526062)\n",
      "train image \n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s - loss: 15476.8955\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 3s - loss: 15334.6172\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 3s - loss: 15101.8545\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 4s - loss: 14838.9463\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 4s - loss: 14595.3525\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 4s - loss: 14401.7070\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 4s - loss: 14257.3877\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 4s - loss: 14151.9395\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 3s - loss: 14073.1797\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 4s - loss: 14003.4590\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 4s - loss: 13934.9023\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 4s - loss: 13865.7021\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 3s - loss: 13789.9922\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 3s - loss: 13710.5625\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 4s - loss: 13630.0029\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 3s - loss: 13545.0752"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "import time\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "img_width = 256\n",
    "img_height = 256\n",
    "nb_epoch = 20\n",
    "train_batchsize = 1 #4\n",
    "train_image_path = \"images/train/\"\n",
    "\n",
    "learning_rate = 1e-3 #1e-3\n",
    "optimizer = Adam(lr=learning_rate,beta_1=0.99)\n",
    "\n",
    "model.compile(optimizer,  dummy_loss)  # Dummy loss since we are learning from regularizes\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "dummy_y = np.zeros((train_batchsize, img_height, img_width, 3)) # Dummy output, not used since we use regularizers to train\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='/Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "for i in range(nb_epoch):\n",
    "    print(\"Epoch : %d\" % (i + 1))\n",
    "\n",
    "    for x in datagen.flow_from_directory(train_image_path, class_mode=None, batch_size=train_batchsize,\n",
    "        target_size=(img_width, img_height), shuffle=False):    \n",
    "        \n",
    "        print(\"train image \")\n",
    "        t1 = time.time()\n",
    "        hist = model.fit(x, dummy_y, batch_size=train_batchsize, nb_epoch=30, verbose=1,callbacks=[tbCallBack])\n",
    "        loss = hist.history['loss'][0]\n",
    "      \n",
    "        print(loss,(time.time() -t1))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
